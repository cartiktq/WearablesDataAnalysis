# WearablesDataAnalysis

This project is an approximation of some of my most recent work. The actual codebase is copyright protected. The project details a training workflow for an unsupervised learning algorithm. It contains pseudocode, for a collection of Python classes, each of which can be containerized to perform the following steps of the workflow:

1) Python class 2, which collects real-time weather data such as temperature, heat index, wind chill, and humidity from weather sources, 
2) Python class 3 uses agentic API to extract data in CSV format from a static database (noSQL like DynamoDB) containing subject demographics data such as age, sex, gender, and ethnicity, physical parameters such as height, weight, and body surface area, for the same cohort of subjects as in (1) above
3) Python class 4 uses agentic API to extract data in CSV format from a clinical data warehouse in Amazon Redshift that contains  information such as diagnosis, prescriptions, lab test results, and invokes a separate agent (Python class 4a using Agentic API), which uses an LLM API such as OpenAI API to summarize rich-text clinical notes and extracts clinical codes such as ICD-9/10, SNOMED CT, RxNORM, and CPT codes from the notes, for the same cohort of subjects as in (1) above. All of this information is collated and outputted in CSV format
4) Python Class 5, which implements an appropriate clustering algorithm, after performing variable selection (not PCA) that uses the parameters extracted from two information sources: DEMOGRAPHICS AND CLINICAL DATA (extracted by Agents 2 and 3 and 3a) to stratify the subject cohort
5) Python Class 6, which evaluates the performance of the clustering algorithm and performs hyperparameter tuning and stops the ML training when the performance metric (F-score) levels off 
6) Python Class 7, which outputs the details of the clusters generated by Python Class 4, 
7) Python Class 8, which uses the T-SNE algorithm and the Seaborn package to create and display a visualization of the generated clusters in three dimensions
8) Python Class 9, which uses an LLM API, such as OpenAI API or Gemini, to look at the patient parameters of the subject cohorts in each of the clusters, to generate a text summary describing the unique characters of each group
9) Python Class 10, which takes as input the streaming wearables data and outputs trends using sliding windows and other patterns of interest

As mentioned before, each class can be containerized with Docker, which can then be composed into an orchestrated workflow implemented in Kubernetes. The template Dockerfiles for some of the Docker images and a putative Kubernetes workflow to orchestrate the sequential execution of these containers is also included

A separate workflow:  
1. takes the output from wearables,
2. performs moving window averages on the incoming data to create a data frame
3. inputs the data feame to a ISolation Forest algorithm to detect outliers and make predictions,
4. which are then output to a CSV file. 

This second workflow is bootstrapped i.e., the predictor trains in the beginning with unlabelled data. The performance of the anomaly detector/predictor improves when adverse events or non-events are recorded for the subjects and the recorded false positives, false negatives, etc. are used in a feedback loop. 


